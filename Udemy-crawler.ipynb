{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from IPython.display import Javascript\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b26aa5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<center><h1><b>MarkUp</b></h1></center>\n",
    "\n",
    "---\n",
    "\n",
    "- Udemy site is using in technology called \"dynamic JavaScript\" which means the website is not fully loadded\n",
    "- when the user enters the course he would like to get.\n",
    "- BeautifulSoup could not handle the \"dynamic JavaScript\" properly and therefore needed to be used the package \n",
    "- of Selenium\n",
    "- The code is organized in such a way:\n",
    "- run_web_driver ==> The code which runs the chrome driver with all the configurations\n",
    "- get_url_content ==> get the html content\n",
    "- create_soup_object ==> create BeautifulSoup object\n",
    "- get_total_number_of_pages ==> when going over name of course in the search then you need to find out how many pages do you have. for example: for python course there will be 500 pages so we would glad to know how many pages to extract their links\n",
    "- extract_links ==> after getting the html going to the right element and build from it the URLS of the courses\n",
    "- write_to_file ==> write the URLS to UDEMY_URLS file in order to make API requests afterwards\n",
    "- forward_to_next_page ==> forward to next page in the udemy site.. happeens when there is a success/failure in getting the URL name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd5a65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Anaconda3\\envs\\mlcourse\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error during links extraction\n",
      "error during links extraction\n",
      "An exception occurred during driver.get url\n"
     ]
    }
   ],
   "source": [
    "#global variables\n",
    "global page_num\n",
    "page_num = 1\n",
    "global number_pages\n",
    "number_pages = -1\n",
    "global num_of_tries\n",
    "num_of_tries = 0\n",
    "\n",
    "###################################################################\n",
    "####################### courses names for query ###################\n",
    "###################################################################\n",
    "#####[python, css, react, javascript, java, c#, c++, testing]######\n",
    "###################################################################\n",
    "global courses_names\n",
    "courses_names = ['python', 'css', 'react', 'javascript', 'java', 'c%23', 'c%2B%2B', 'testing']\n",
    "global course_index\n",
    "course_index = 0\n",
    "\n",
    "def run_web_driver():\n",
    "    opts = Options()\n",
    "    os.environ['WDM_LOG_LEVEL'] = '0'\n",
    "    opts.add_argument(\"start-maximized\")\n",
    "    opts.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "#     driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    agent = driver.execute_script(\"return navigator.userAgent\")\n",
    "    opts.add_argument(\"user-agent=\" + agent)\n",
    "    driver = webdriver.Chrome(chrome_options = opts)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(8)\n",
    "    get_url_content(driver)\n",
    "\n",
    "def get_url_content(driver):\n",
    "    global page_num\n",
    "    global courses_names\n",
    "    global course_index\n",
    "\n",
    "    url = f'https://www.udemy.com/courses/search/?p={page_num}&q={courses_names[course_index]}&src=ukw'\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(10)\n",
    "        create_soup_object(driver)\n",
    "    except:\n",
    "        print(\"An exception occurred during driver.get url\")\n",
    "        forward_to_next_page()\n",
    "\n",
    "def create_soup_object(driver):\n",
    "    global number_pages\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    if soup == None:\n",
    "        driver.close()\n",
    "        run_web_driver()\n",
    "    driver.close()\n",
    "    \n",
    "    if number_pages == -1: \n",
    "        get_total_number_of_pages(soup)\n",
    "    else:\n",
    "        extract_links(soup)\n",
    "\n",
    "def get_total_number_of_pages(soup):\n",
    "    global number_pages\n",
    "\n",
    "    number_pages_soup = soup.find('span', attrs={'class':'udlite-heading-sm pagination--page--1H0A2'})\n",
    "    if number_pages_soup == None:\n",
    "        run_web_driver()\n",
    "        \n",
    "    number_pages = int(number_pages_soup.text)\n",
    "    extract_links(soup)\n",
    "\n",
    "def extract_links(soup):\n",
    "    global num_of_tries\n",
    "\n",
    "    links = [item['href'] for item in soup.select('body div h3 a')]\n",
    "    if not links:\n",
    "        num_of_tries = num_of_tries + 1\n",
    "        if num_of_tries == 3:\n",
    "            print('error during links extraction')\n",
    "            forward_to_next_page()\n",
    "        else:\n",
    "            run_web_driver()\n",
    "    else:\n",
    "        num_of_tries = 0\n",
    "        write_to_file(links)\n",
    "\n",
    "def write_to_file(links):\n",
    "    with open('Udemy_URLS.csv', 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for link in links:            \n",
    "            writer.writerow({'www.udemy.com' + link})\n",
    "    forward_to_next_page()\n",
    "\n",
    "def forward_to_next_page():\n",
    "    global page_num\n",
    "    global number_pages\n",
    "    global num_of_tries\n",
    "    global courses_names\n",
    "    global course_index\n",
    "\n",
    "    if page_num <= number_pages:\n",
    "        page_num = page_num + 1\n",
    "        run_web_driver()\n",
    "    else:\n",
    "        page_num = 1\n",
    "        number_pages = -1\n",
    "        num_of_tries = 0\n",
    "        course_index = course_index + 1\n",
    "        if(course_index < len(courses_names)):\n",
    "            run_web_driver()\n",
    "        else:\n",
    "            print('finished!')\n",
    "            \n",
    "            \n",
    "#start of the program\n",
    "run_web_driver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
